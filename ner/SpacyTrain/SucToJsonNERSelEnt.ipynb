{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def convert(xml):\n",
    "\n",
    "    tree = ET.parse(xml)\n",
    "    root = tree.getroot()\n",
    "    spacyJson = []\n",
    "    ents = [\"PRS\", \"ORG\", \"LOC\", \"TME\"]\n",
    "    \n",
    "    for paragraph in root.iter('text'):\n",
    "        paragraphDict = {}\n",
    "        sentencesList = []\n",
    "        \n",
    "        sentencesDict = {}\n",
    "        paragraphsList = []\n",
    "        \n",
    "        for sent in paragraph.iter('sentence'):\n",
    "            sentsDict = {}    \n",
    "            tokensDict = {}\n",
    "            tokensList = []\n",
    "            for child in sent:\n",
    "                if child.tag == 'name':\n",
    "                    for token in child.iter('w'):\n",
    "                        nameDict = {'orth': token.text, 'tag': token.attrib['msd'].replace('.', '|'), \"ner\": \"O\"}\n",
    "                        tokensList.append(nameDict)\n",
    "                elif child.tag == 'ne' and child.attrib['type'] in ents:\n",
    "                    entityTokenList = child.attrib['name'].split(' ')\n",
    "                    for token in child.iter('w'):\n",
    "                        neDict = {'orth': token.text, 'tag': token.attrib['msd'].replace('.', '|')}\n",
    "                        if len(entityTokenList) == 1:\n",
    "                            neDict['ner'] = 'U-' + child.attrib['type']\n",
    "                            tokensList.append(neDict)\n",
    "                            continue\n",
    "                        elif token.text == entityTokenList[len(entityTokenList) - 1]:\n",
    "                            neDict['ner'] = 'L-' + child.attrib['type']\n",
    "                            tokensList.append(neDict)\n",
    "                            continue\n",
    "                        elif token.text == entityTokenList[0]:\n",
    "                            neDict['ner'] = 'B-' + child.attrib['type']\n",
    "                            tokensList.append(neDict)\n",
    "                            continue\n",
    "                        else:\n",
    "                            neDict['ner'] = 'I-' + child.attrib['type']\n",
    "                            tokensList.append(neDict)\n",
    "                elif child.tag == 'ne':\n",
    "                    for token in child.iter('w'):\n",
    "                        tokenDict = {'orth': token.text, 'tag': token.attrib['msd'].replace('.', '|'), \"ner\": \"O\"}\n",
    "                        tokensList.append(tokenDict)\n",
    "                elif child.tag == 'w':\n",
    "                    tokenDict = {'orth': child.text, 'tag': child.attrib['msd'].replace('.', '|'), \"ner\": \"O\"}\n",
    "                    tokensList.append(tokenDict)\n",
    "                else:\n",
    "                    continue\n",
    "            sentsDict['tokens'] = tokensList\n",
    "            sentencesList.append(sentsDict)\n",
    "        sentencesDict['sentences'] = sentencesList\n",
    "        paragraphsList.append(sentencesDict)\n",
    "        paragraphDict['paragraphs'] = paragraphsList\n",
    "        spacyJson.append(paragraphDict)\n",
    "    \n",
    "    return spacyJson"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def printToFile(file, content):\n",
    "    with open(file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(content, f, ensure_ascii=False, indent=2)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "spacyTrain = convert('../Data/Datasets/Common/suc3train.xml')\n",
    "\n",
    "printToFile('../Data/Datasets/ner/suc30train.json', spacyTrain)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}