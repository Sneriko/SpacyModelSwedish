{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "tree = ET.parse('../../Data/Datasets/Common/suc3train.xml')\n",
    "root = tree.getroot()\n",
    "spacyJson = []\n",
    "ents = [\"PRS\", \"ORG\", \"LOC\", \"TME\", \"MSR\", \"WRK\", \"EVN\", \"OBJ\"]\n",
    "sentsList = []\n",
    "\n",
    "for sent in root.iter('sentence'):\n",
    "    tokensList = []\n",
    "    for child in sent:\n",
    "        if child.tag == 'name':\n",
    "            for token in child.iter('w'):\n",
    "                nameDict = {'orth': token.text, 'tag': token.attrib['msd'].replace('.', '|'), \"ner\": \"O\"}\n",
    "                tokensList.append(nameDict)\n",
    "        elif child.tag == 'ne' and child.attrib['type'] in ents:\n",
    "            entityTokenList = child.attrib['name'].split(' ')\n",
    "            for token in child.iter('w'):\n",
    "                neDict = {'orth': token.text, 'tag': token.attrib['msd'].replace('.', '|')}\n",
    "                if len(entityTokenList) == 1:\n",
    "                    neDict['ner'] = 'U-' + child.attrib['type']\n",
    "                    tokensList.append(neDict)\n",
    "                    continue\n",
    "                elif token.text == entityTokenList[len(entityTokenList) - 1]:\n",
    "                    neDict['ner'] = 'L-' + child.attrib['type']\n",
    "                    tokensList.append(neDict)\n",
    "                    continue\n",
    "                elif token.text == entityTokenList[0]:\n",
    "                    neDict['ner'] = 'B-' + child.attrib['type']\n",
    "                    tokensList.append(neDict)\n",
    "                    continue\n",
    "                else:\n",
    "                    neDict['ner'] = 'I-' + child.attrib['type']\n",
    "                    tokensList.append(neDict)\n",
    "        elif child.tag == 'ne':\n",
    "            for token in child.iter('w'):\n",
    "                tokenDict = {'orth': token.text, 'tag': token.attrib['msd'].replace('.', '|'), \"ner\": \"O\"}\n",
    "                tokensList.append(tokenDict)\n",
    "        elif child.tag == 'w':\n",
    "            tokenDict = {'orth': child.text, 'tag': child.attrib['msd'].replace('.', '|'), \"ner\": \"O\"}\n",
    "            tokensList.append(tokenDict)\n",
    "        else:\n",
    "            continue\n",
    "    sentsList.append(tokensList)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "\n",
    "with open('../../Data/Datasets/ner/SUC3trainCONLL2003', 'w', encoding='utf-8') as f:\n",
    "    f.write('-DOCSTART- -X- O O' + '\\n\\n')\n",
    "    for sent in sentsList:\n",
    "        for token in sent:\n",
    "            f.write(token['orth'] + ' ' + token['tag'] + ' ' + 'O' + ' ' + token['ner'] + '\\n')\n",
    "        f.write('\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}