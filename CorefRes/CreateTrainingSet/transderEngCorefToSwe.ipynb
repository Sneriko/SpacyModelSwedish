{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pickle\n",
    "import neuralcoref.train.document as dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "with open('corefSpansObject', 'rb') as f:\n",
    "    corefSpans = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "sweCorp = ''\n",
    "\n",
    "with open('../Data/Datasets/Europarl/Documents/ep-00-01-17/ep-00-01-17-sv.txt') as sweDoc:\n",
    "    for line in sweDoc:\n",
    "        sweCorp = sweCorp + line\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "nlp = spacy.load('../Models/SwedishModel')\n",
    "doc = nlp(sweCorp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "corefSpansSwe = []\n",
    "numOfCorefs = 0\n",
    "for cluster in corefSpans:\n",
    "    corefClusterSwe = []\n",
    "    for mention in cluster:\n",
    "        corefSwe = []\n",
    "        startOfLine = 0\n",
    "        endOfLine = 0\n",
    "        lineText = ''\n",
    "        mentionText = ''\n",
    "        if mention[0] != -1:\n",
    "            for tok in range(mention[0], mention[-1]):\n",
    "                mentionText = mentionText + doc[tok].text + ' '\n",
    "            mentionText.rstrip()\n",
    "\n",
    "            startOfLine = mention[0]\n",
    "            endOfLine = mention[-1]\n",
    "            while doc[startOfLine].text != '\\n':\n",
    "                startOfLine -= 1\n",
    "            startOfLine += 1\n",
    "            while doc[endOfLine].text != '\\n':\n",
    "                endOfLine += 1\n",
    "\n",
    "            for tok in range(startOfLine, endOfLine):\n",
    "                lineText = lineText + doc[tok].text + ' '\n",
    "            lineText.rstrip()\n",
    "\n",
    "        mentionSpanDoc = nlp(mentionText)\n",
    "        lineDoc = nlp(lineText)\n",
    "\n",
    "        mentionsInSpan = dc.extract_mentions_spans(mentionSpanDoc, [])\n",
    "        mentionsInLine = dc.extract_mentions_spans(lineDoc, [])\n",
    "\n",
    "        if len(mentionsInSpan) == 0:\n",
    "            continue\n",
    "\n",
    "        invalidCoref = False\n",
    "        \n",
    "        \"\"\"for span in mentionsInLine:\n",
    "            if (span.end + startOfLine) > mention[1] > (span.start + startOfLine) > mention[0] or (span.start + startOfLine) < mention[0] < (span.end + startOfLine) < mention[1]:\n",
    "                invalidCoref = True\"\"\"\n",
    "        \n",
    "        maxLength = 0\n",
    "        maxSpan = 0\n",
    "        for span in mentionsInSpan:\n",
    "            if span.end - span.start > maxLength:\n",
    "                maxLength = span.end - span.start\n",
    "                maxSpan = span\n",
    "\n",
    "        for span in mentionsInSpan:\n",
    "            if span.start < maxSpan.start or span.end > maxSpan.end:\n",
    "                invalidCoref = True\n",
    "\n",
    "        if invalidCoref:\n",
    "            continue\n",
    "        elif not invalidCoref:\n",
    "            corefSwe.append(maxSpan.start + mention[0])\n",
    "            corefSwe.append(maxSpan.end + mention[0])\n",
    "            corefClusterSwe.append(corefSwe)\n",
    "\n",
    "    if len(corefClusterSwe) > 1:\n",
    "        corefSpansSwe.append(corefClusterSwe)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "noOfCorefsEng = 0\n",
    "for sublist in corefSpans:\n",
    "    for span in sublist:\n",
    "        noOfCorefsEng += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "noOfCorefsSwe = 0\n",
    "for sublist in corefSpansSwe:\n",
    "    for span in sublist:\n",
    "        noOfCorefsSwe += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "with open('corefSpansSweObject', 'wb') as f:\n",
    "    pickle.dump(corefSpansSwe, f)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}